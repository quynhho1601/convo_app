# Convo

Convo is an open-source visual tool that helps programmers organize, inspect, and consolidate multi-turn prompts from LLM chat histories into reusable prompt artifacts.

## ğŸ› ï¸ What it does

Convo allows users to import past LLM chat histories and interact with them visually:

- Extracts prompts into numbered nodes

- Organizes prompts in a 2D workspace

- Highlights redundancy and missing components

- Supports prompt consolidation and reuse

- Saves generated prompts in a reusable log

## Demo

Video Link: https://drive.google.com/file/d/1oO_w5WH79VW9iOEg0KGgV_Enkf1s9mEt/view?usp=sharing

## ğŸ“ Repository Structure

```text
convo/
â”œâ”€â”€ back_end/                 # Backend (Flask)
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ routes/           # API route definitions
â”‚   â”‚   â”‚   â”œâ”€â”€ classification.py
â”‚   â”‚   â”‚   â””â”€â”€ generate_prompt.py
â”‚   â”‚   â”œâ”€â”€ services/         # Core business logic
â”‚   â”‚   â”‚   â”œâ”€â”€ classification_service.py
â”‚   â”‚   â”‚   â””â”€â”€ promptgen_service.py
â”‚   â”‚   â””â”€â”€ utils/            # Configuration and helpers
â”‚   â”‚       â””â”€â”€ config.py
â”‚   â”œâ”€â”€ run.py                # Backend entry point
â”‚   â”œâ”€â”€ test_env.py           # Environment test script
â”‚   â”œâ”€â”€ requirements.txt      # Python dependencies
â”‚   â”œâ”€â”€ .env                  # Backend environment variables
â”‚   â””â”€â”€ venv/                 # Python virtual environment (local)
â”‚
â”œâ”€â”€ front_end/                # Frontend (React + TypeScript)
â”‚   â”œâ”€â”€ components/           # UI components
â”‚   â”œâ”€â”€ css/                  # Stylesheets
â”‚   â”œâ”€â”€ src/                  # Frontend source code
â”‚   â”œâ”€â”€ App.tsx               # Main React component
â”‚   â”œâ”€â”€ index.tsx             # Frontend entry point
â”‚   â”œâ”€â”€ index.html            # HTML template
â”‚   â”œâ”€â”€ metadata.json         # App metadata
â”‚   â”œâ”€â”€ package.json          # Frontend dependencies
â”‚   â”œâ”€â”€ package-lock.json
â”‚   â”œâ”€â”€ tsconfig.json         # TypeScript configuration
â”‚   â””â”€â”€ .env.local            # Frontend environment variables
â”‚
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```
## ğŸ› ï¸ Development

### Prerequisites
- Node.js (v18+)
- npm
- (Optional) API key for an LLM provider (used for prompt consolidation)

### â–¶ï¸ Running the Project Locally

#### 1. Clone the Repository
```bash
git https://github.com/quynhho1601/convo_app.git
cd convo_app
```

#### 2. Start the Backend
```bash
cd back_end
conda activate <your-python-env>
python run.py 
```

#### 3. Start the Frontend
```bash
cd front_end
npm install
npm run dev
```

## ğŸ“‚ Importing Chat Histories

Convo works with exported chat histories from common LLM platforms:

- **Claude**: [Settings â†’ Privacy â†’ Export data](https://support.claude.com/en/articles/9450526-how-can-i-export-my-claude-data) (official documentation)
- **ChatGPT**: [Settings â†’ Data Controls â†’ Export Data](https://help.openai.com/en/articles/7260999-how-do-i-export-my-chatgpt-history-and-data) (official OpenAI documentation)
- **Gemini**: [Share & export responses](https://support.google.com/gemini/answer/14184041) or use [Google Takeout](https://takeout.google.com/) (official Google documentation)

Paste the exported chat transcript into the Import Chat interface to begin.

## ğŸš€ How to Use

1. Import a multi-turn chat history
2. Use **Classification Mode** to filter relevant prompts
3. Organize prompts as nodes in the visual workspace
4. Use **Canvas Mode** to identify missing components
5. Select prompts and click **Create Ideas** to generate a consolidated prompt
6. Review and manage results in the **Prompt Log**

## ğŸ¤ Contributing

This is an open-source project. Issues and pull requests are welcome!

## ğŸ“„ License

MIT License